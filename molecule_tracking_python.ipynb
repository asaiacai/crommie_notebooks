{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, unicode_literals, print_function  # for compatibility with Python 2 and 3\n",
    "\n",
    "import matplotlib as mpl \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Optionally, tweak styles.\n",
    "mpl.rc('figure',  figsize=(10, 5))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series  # for convenience\n",
    "import os\n",
    "import seaborn as sns\n",
    "# equivalent to rcParams['animation.html'] = 'html5'\n",
    "rc('animation', html='html5')\n",
    "import pims\n",
    "import pySPM as spm \n",
    "import trackpy as tp\n",
    "import glob\n",
    "from sxmreader import SXMReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_range = range(1, 1+200)\n",
    "N = len(n_range)\n",
    "SXM_PATH = [\"electromigration_30/Image_{0:03}.sxm\".format(i) for i in n_range]\n",
    "frames = SXMReader(SXM_PATH)\n",
    "molecule_size = 11\n",
    "detect_kwargs = {\n",
    "    'minmass' : 2,\n",
    "    'maxsize' : 4,\n",
    "    'separation' : 5,\n",
    "}\n",
    "f = tp.batch(frames[:], molecule_size, **detect_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(3, 5))\n",
    "idx = 0\n",
    "ax = tp.annotate(f[f['frame']==idx], frames[idx], plot_style={'markersize':1})\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_kws = {\n",
    "    'search_range' : 30,\n",
    "    'adaptive_stop' : 2.0,\n",
    "    'adaptive_step' : 0.95,\n",
    "}\n",
    "t = tp.link(f, **search_kws)\n",
    "plt.figure()\n",
    "tp.mass_size(t.groupby('particle').mean()); # convenience function -- just plots size vs. mass\n",
    "tp.mass_ecc(t.groupby('particle').mean()); # convenience function -- just plots size vs. mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_mass, max_mass = 9, 14\n",
    "min_size, max_size = 1.8, 2.2\n",
    "min_ecc, max_ecc = 0.05, 0.3\n",
    "t1 = t[t['ecc'].between(min_ecc, max_ecc) &\n",
    "       t['size'].between(min_size, max_size) & \n",
    "       t['mass'].between(min_mass, max_mass)]\n",
    "t2 = tp.filter_stubs(t, 30)\n",
    "# Compare the number of particles in the unfiltered and filtered data.\n",
    "print('Before:', t['particle'].nunique())\n",
    "print('After:', t2['particle'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "plt.rcParams['figure.dpi'] = 150  \n",
    "plt.ioff()\n",
    "fig=plt.figure(figsize=(8, 6), dpi=120)\n",
    "ax1=plt.axes(xlim=(0, 256), ylim=(0, 256), frameon=False)\n",
    "plt.axis('off')\n",
    "ln, = ax1.plot([], [], lw=3)\n",
    "ax1.set_prop_cycle(color=['g', 'r', 'c', 'm', 'y', 'k'])\n",
    "def animate(i):\n",
    "    plt.cla()\n",
    "    tp.plot_traj(t2[(t2['frame']<=1)], superimpose=frames[i], label=False, ax=ax1, plot_style={'alpha' : 1})\n",
    "    ax1.set_prop_cycle(color=['g', 'r', 'c', 'm', 'y', 'k'])\n",
    "    plt.imshow(frames[i], cmap='gray')\n",
    "# Set up formatting for the movie files\n",
    "Writer = matplotlib.animation.writers['ffmpeg']\n",
    "writer = Writer(fps=5, metadata=dict(artist='Me'), bitrate=1800)\n",
    "line_ani = matplotlib.animation.FuncAnimation(fig, animate, frames=30)\n",
    "# line_ani.save('claymation.mp4', writer=writer)\n",
    "line_ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tp.compute_drift(t2)\n",
    "tm = tp.subtract_drift(t2.copy(), d)\n",
    "tm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = tp.imsd(tm, frames.meters_per_pixel * 1e6, 1) * 1e6\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "import matplotlib\n",
    "matplotlib.rc('font', **font)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "ax.plot(im.index, im , 'k-', alpha=0.1)  # black lines, semitransparent\n",
    "ax.set(ylabel=r'$\\langle \\Delta r^2 \\rangle$ [nm$^2$]',\n",
    "       xlabel='lag time $t$')\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_yscale('log')\n",
    "em = tp.emsd(tm, frames.meters_per_pixel * 1e6, 1) * 1e6\n",
    "ax.plot(em.index, em, 'o')\n",
    "ax.set_xlim(0, 25)\n",
    "ax.set_ylim(0, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(r'$\\langle \\Delta r^2 \\rangle$ [nm$^2$]')\n",
    "plt.xlabel('lag time $t$');\n",
    "tp.utils.fit_powerlaw(em[:30])  # performs linear best fit in log space, plots]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = tp.compute_drift(t2)\n",
    "t3 = tp.subtract_drift(t2.copy(), d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "diff_class = {0 : 'fbm', 1 : 'brownian', 2 : 'ctrw'}\n",
    "def classification_on_real(dx):\n",
    "    N=np.shape(dx)[0]\n",
    "    net_file = '../moire_walk/models/classification_model_30.h5'\n",
    "    model = load_model(net_file)\n",
    "    predictions = []\n",
    "    y_preds = []\n",
    "    for j in range(N):\n",
    "        dummy = np.zeros((1,29,1))\n",
    "        dummy[0,:,:] = np.reshape(dx[j,:], (29, 1))\n",
    "        y_pred = model.predict(dummy) # get the results for 1D \n",
    "        ymean = np.mean(y_pred,axis=0) # calculate mean prediction of N-dimensional trajectory \n",
    "        prediction = np.argmax(ymean,axis=0) # translate to classification\n",
    "        predictions.append(prediction)\n",
    "        print('particle {} --> {}'.format(j + 1, diff_class[prediction]))\n",
    "        print('y_pred {}'.format(y_pred))\n",
    "        y_preds.append(y_pred[0])\n",
    "    return y_preds\n",
    "\n",
    "# [print(x.shape) for x in paths]\n",
    "# long_paths = [x[:30,1] for x in paths if x.shape[0] > 30]\n",
    "num_steps = t3.particle.value_counts()\n",
    "long_track_id = num_steps.index[num_steps >= 30]\n",
    "long_paths = [t3[t3.particle == idx].x.values[:30] for idx in long_track_id]\n",
    "x1 = np.array(long_paths)\n",
    "x1 = x1-np.mean(x1)     \n",
    "x_n = x1\n",
    "dx = np.diff(x_n)\n",
    "y_preds = classification_on_real(dx)\n",
    "print(np.mean(y_preds, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_on_real(dx):\n",
    "    N=np.shape(dx)[0]\n",
    "    net_file = 'models/20_alpha_model.h5'\n",
    "    model = load_model(net_file)\n",
    "    predictions = []\n",
    "    for j in range(N):\n",
    "        dummy = np.zeros((1,19,1))\n",
    "        dummy[0,:,:] = np.reshape(dx[j,:], (19, 1))\n",
    "        y_pred = model.predict(dummy) # get the results for 1D \n",
    "        ymean = np.mean(y_pred,axis=0) # calculate mean prediction of N-dimensional trajectory \n",
    "        predictions.append(ymean)\n",
    "        print('particle {} --> {}'.format(j + 1, ymean))\n",
    "    return predictions\n",
    "# [print(x.shape) for x in paths]\n",
    "# long_paths = [x[:30,1] for x in paths if x.shape[0] > 30]\n",
    "num_steps = t3.particle.value_counts()\n",
    "long_track_id = num_steps.index[num_steps >= 20]\n",
    "long_paths = [t3[t3.particle == idx].x.values[:20] for idx in long_track_id]\n",
    "x1 = np.array(long_paths)\n",
    "x1 = x1-np.mean(x1)     \n",
    "x_n = x1\n",
    "dx = np.diff(x_n)\n",
    "alphas = np.array(alpha_on_real(dx))\n",
    "np.mean(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "displacements = np.concatenate(paths)*frames.meters_per_pixel*1e9\n",
    "dists = np.sqrt(np.einsum(\"ij, ij->i\", displacements, displacements))\n",
    "print(\"The mean square displacement is: \", (dists**2).mean(), \"nm\")\n",
    "plt.title(\"total displacement distribution\")\n",
    "plt.xlabel(\"displacement (nm)\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.hist(dists, bins=50);\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.hist2d(displacements.T[0], displacements.T[1], bins = 15);\n",
    "plt.figure(figsize=(5,5));\n",
    "import seaborn as sns\n",
    "displacement_df = pd.DataFrame(displacements, columns=['dx','dy'])\n",
    "#g = sns.jointplot(x=\"dx\", y=\"dy\", data=displacement_df)\n",
    "plt.scatter(displacement_df['dx'],displacement_df['dy'])\n",
    "plt.xlim(-0.5,0.5)\n",
    "plt.ylim(-0.5,0.5)\n",
    "plt.grid()\n",
    "ax.set_aspect('equal', 'box')\n",
    "plt.figure(figsize=(5,5));\n",
    "plt.scatter(displacement_df['dx'],displacement_df['dy'])\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-2,2)\n",
    "plt.grid()\n",
    "ax.set_aspect('equal', 'box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.optimize import curve_fit\n",
    "def msd(df):\n",
    "    df['time'] = df['frame'] - df['frame'].iloc[0]\n",
    "    x0, y0 = df.x.iloc[0], df.y.iloc[0]\n",
    "    df['msd'] = (df.x - x0) ** 2 + (df.y - y0) ** 2\n",
    "    return df\n",
    "msds = t3.groupby('particle').apply(lambda x : msd(x))\n",
    "# plt.figure(figsize=(5, 5))\n",
    "sns.lineplot(data=msds, x='time', y='msd')\n",
    "# sns.regplot(data=msds, x='time', y='msd', scatter=False)\n",
    "ser = msds.groupby('time').msd.mean()\n",
    "# ser.plot()\n",
    "# msds.groupby('time').size().plot()\n",
    "# (ser.iloc[1:] / 30).plot()\n",
    "END_RANGE = 60\n",
    "reg = LinearRegression(fit_intercept = False).fit(ser.index.values[1:5].reshape(-1, 1), ser.values[1:5])\n",
    "def f(t, a, b):\n",
    "    return a * t ** b\n",
    "popt, pcov = curve_fit(f, ser.index.values[1:END_RANGE], ser.values[1:END_RANGE], bounds=[[0, 0], [np.inf, 1]])\n",
    "print(popt)\n",
    "plt.plot(ser.index.values, reg.predict(ser.index.values.reshape(-1, 1)), label='linear fit')\n",
    "plt.plot(ser.index.values, f(ser.index.values, *popt), label='power law fit')\n",
    "plt.xlim(0, END_RANGE)\n",
    "# plt.ylim(0, 500)\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, msds1,  line1, fit1 = ser.index.values, msds, reg.predict(ser.index.values.reshape(-1, 1)), f(ser.index.values, *popt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bl = tp.is_typical(im, 10, 0, 0.9)\n",
    "# typical_tm = tm[tm.particle.isin(bl.index[bl].tolist())]\n",
    "im = tp.imsd(t3, 1e9*frames.meters_per_pixel, 1)  # microns per pixel = 100/285., frames per second = 24\n",
    "em = tp.emsd(t3, frames.meters_per_pixel*1e9, 1, max_lagtime=30) # microns per pixel = 100/285., frames per second = 24\n",
    "N = tp.emsd(t3, frames.meters_per_pixel*1e9, 1, detail=True, max_lagtime=30).set_index('lagt').N\n",
    "ax = sns.regplot(em.index.values, em)\n",
    "ax.plot(im.index, im, 'k-', alpha=0.1)  # black lines, semitransparent\n",
    "# ax.plot(line, line)\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_yscale('log')\n",
    "ax.set(ylabel=r'$\\langle \\Delta r^2 \\rangle$ [nm$^2$]',\n",
    "       xlabel='lag time $t$')\n",
    "ax.errorbar(em.index.values, em, yerr=em / np.sqrt(N), ls='none')\n",
    "#ax.set(ylim=(1e-2, 10));\n",
    "plt.title(\"MSD, \" + SXM_PATH[0] + \" to {}\".format(n_range[-1]))\n",
    "# frame_id = 0\n",
    "# filename = frames.filenames[frame_id]\n",
    "# base_path = filename[:filename.find('/')]\n",
    "# path = os.path.join(\"output\", base_path)\n",
    "# if not os.path.exists(path):\n",
    "#     os.makedirs(path)\n",
    "# fig.savefig(os.path.join(path, 'diffusion.png'))\n",
    "# tmp = t4[t4['particle'] == 0] * frames.meters_per_pixel*1e6\n",
    "# r2 = (tmp.x - tmp.iloc[0].x) ** 2 + (tmp.y - tmp.iloc[0].y)**2\n",
    "# plt.plot(r2)\n",
    "from scipy.stats import linregress\n",
    "result, _, _, _, _ = linregress(em.index, em)\n",
    "result\n",
    "result = tp.utils.fit_powerlaw(em)  # performs linear best fit in log space, plots]\n",
    "print(result['A'])\n",
    "print(result['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(t3.groupby('particle').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pvariation(df, p, n, t=None):\n",
    "    \"\"\"p-variation for finite n.\n",
    "    df: each trajectory data file\n",
    "    p: power in p-variation formula\n",
    "    n: n is the power in 2^n \n",
    "    t: max measurement time\n",
    "    Frames beyond the highest power of 2 available are ignored.\n",
    "    All intervals are constructed to be of equal length. T is assumed,\n",
    "    without loss of generality, to equal the total number of frames included.\n",
    "    \n",
    "    \"\"\"\n",
    "    maxn = int(np.log2(len(df)) // 1)\n",
    "    T = 2**maxn\n",
    "    if t is None:\n",
    "        t = T\n",
    "    x = np.array(df['x'])\n",
    "    y = np.array(df['y'])\n",
    "    dt = T // 2**n\n",
    "    ts = np.arange(2**n)*dt\n",
    "    ts = ts[ts < t]  # Ignore frames greater than t\n",
    "    total = 0.\n",
    "    for i in range(len(ts) - 1):\n",
    "        total += np.abs(x[ts[i+1]] - x[ts[i]])**p\n",
    "    return total\n",
    "\n",
    "tmp = t3[t3.particle == 1]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "for j in [4, 5, 6]:\n",
    "    v_t = []\n",
    "    for i in range(2 ** 6):\n",
    "        v_t.append(pvariation(tmp, 2, j, t=i))\n",
    "    plt.plot(v_t, label=\"n = {}\".format(j))\n",
    "plt.legend()\n",
    "plt.xlim(0, 300)\n",
    "plt.xlim(0, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "plt.ylabel(r'$\\langle \\Delta r^2 \\rangle$ [$\\mu$m$^2$]')\n",
    "plt.xlabel('lag time $t$');\n",
    "plt.title(\"MSD, \" + SXM_PATH[0] + \" to {}\".format(n_range[-1]))\n",
    "tp.utils.fit_powerlaw(em)  # performs linear best fit in log space, plots]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "displacements = np.concatenate(paths)*frames.meters_per_pixel*1e9\n",
    "dists = np.sqrt(np.einsum(\"ij, ij->i\", displacements, displacements))\n",
    "print(\"The mean square displacement is: \", (dists**2).mean(), \"nm\")\n",
    "plt.title(\"total displacement distribution\")\n",
    "plt.xlabel(\"displacement (nm)\")\n",
    "plt.ylabel(\"count\")\n",
    "sns.distplot(dists, fit=norm, kde=False, bins=50);\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.hist2d(displacements.T[0], displacements.T[1], bins = 15);\n",
    "plt.figure(figsize=(5,5));\n",
    "import seaborn as sns\n",
    "displacement_df = pd.DataFrame(displacements, columns=['dx','dy'])\n",
    "#g = sns.jointplot(x=\"dx\", y=\"dy\", data=displacement_df)\n",
    "plt.scatter(displacement_df['dx'],displacement_df['dy'])\n",
    "plt.xlim(-0.5,0.5)\n",
    "plt.ylim(-0.5,0.5)\n",
    "plt.grid()\n",
    "ax.set_aspect('equal', 'box')\n",
    "plt.figure(figsize=(5,5));\n",
    "plt.scatter(displacement_df['dx'],displacement_df['dy'])\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-2,2)\n",
    "plt.grid()\n",
    "plt.title('{} to {}'.format(SXM_PATH[0], n_range[-1]))\n",
    "ax.set_aspect('equal', 'box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting : DONT USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A new version of tp.motion.emsd() that calculates standard deviation.\n",
    "# This function is copied from trackpy. (Please see the trackpy license.)\n",
    "# I [Viva] added the calculation of biased weighted standard deviation.\n",
    "\n",
    "def my_emsd(traj, mpp, fps, max_lagtime=100, detail=False, pos_columns=None):\n",
    "    \"\"\"Compute the ensemble mean squared displacements of many particles.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : DataFrame of trajectories of multiple particles, including\n",
    "        columns particle, frame, x, and y\n",
    "    mpp : microns per pixel\n",
    "    fps : frames per second\n",
    "    max_lagtime : intervals of frames out to which MSD is computed\n",
    "        Default: 100\n",
    "    detail : Set to True to include <x>, <y>, <x^2>, <y^2>. Returns\n",
    "        only <r^2> by default.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Series[msd, index=t] or, if detail=True,\n",
    "    DataFrame([<x>, <y>, <x^2>, <y^2>, msd, N, lagt,\n",
    "               std_<x>, std_<y>, std_<x^2>, std_<y^2>, \n",
    "               std_msd],\n",
    "              index=frame)\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Input units are pixels and frames. Output units are microns and seconds.\n",
    "    \"\"\"\n",
    "    ids = []\n",
    "    msds = []\n",
    "    for pid, ptraj in traj.reset_index(drop=True).groupby('particle'):\n",
    "        msds.append(tp.motion.msd(ptraj, mpp, fps, max_lagtime, True, pos_columns))\n",
    "        ids.append(pid)\n",
    "    msds = pd.concat(msds, keys=ids, names=['particle', 'frame'])\n",
    "    results = msds.mul(msds['N'], axis=0).mean(level=1)  # weighted average\n",
    "    results = results.div(msds['N'].mean(level=1), axis=0)  # weights normalized\n",
    "    # Above, lagt is lumped in with the rest for simplicity and speed.\n",
    "    # Here, rebuild it from the frame index.\n",
    "    \n",
    "    if not detail:\n",
    "        return results.set_index('lagt')['msd']\n",
    "\n",
    "    # Calculation of biased weighted standard deviation\n",
    "    numerator = ((msds.subtract(results))**2).mul(msds['N'], axis=0).sum(level=1)\n",
    "    denominator = msds['N'].sum(level=1) # without Bessel's correction\n",
    "    variance = numerator.div(denominator, axis=0)\n",
    "    variance = variance[['<x>', '<y>', '<x^2>','<y^2>','msd']]\n",
    "    std = np.sqrt(variance)\n",
    "    std.columns = 'std_' + std.columns  \n",
    "\n",
    "    return results.join(std)\n",
    "\n",
    "detailed_emsd = my_emsd(tm, frames.meters_per_pixel*1e6, 1, detail=True, max_lagtime=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "plt.errorbar(detailed_emsd.lagt, \n",
    "             detailed_emsd.msd, \n",
    "             yerr = detailed_emsd.std_msd, \n",
    "             capthick=0, \n",
    "             alpha = 0.7,\n",
    "             linewidth=.2,\n",
    "             label=\"biased weighted standard deviation\")\n",
    "ax2 = plt.subplot(111)\n",
    "ax2.set(ylabel=r'$\\langle \\Delta r^2 \\rangle$ [$\\mu$m$^2$]', xlabel='lag time $\\Delta t$ [s]')\n",
    "ax2.get_xaxis().set_major_formatter(matplotlib.ticker.FormatStrFormatter('%g'))\n",
    "\n",
    "plt.legend(loc=2, fontsize='medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orientation",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
